# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LInXh3veOZWBSkopCFCvNdFY4Jc8cCRj
"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

!kaggle datasets download -d salader/dogs-vs-cats

import zipfile
zip_ref = zipfile.ZipFile('/content/dogs-vs-cats.zip', 'r')
zip_ref.extractall('/content')
zip_ref.close()

import tensorflow as tf
from  tensorflow import keras
from keras import Sequential
from keras import regularizers
from keras.callbacks import EarlyStopping
from keras.layers import Dense ,Conv2D , MaxPooling2D, Flatten, BatchNormalization, Dropout
from keras.regularizers import l2

train_ds=keras.utils.image_dataset_from_directory(
    directory='/content/train',
    labels='inferred',
    label_mode='int',
    batch_size=32,
    image_size=(256,256)
)
validation_ds=keras.utils.image_dataset_from_directory(
    directory='/content/test',
    labels='inferred',
    label_mode='int',
    batch_size=32,
    image_size=(256,256)
)

#Normalization
def process (image, label):
  image=tf.cast(image/255., tf.float32)
  return image, label
  train_ds=train_ds.map(process)
  validation_ds-=validation_ds.map(process)

model = Sequential()

model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(256,256,3), kernel_regularizer=l2(.01)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))

model.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))

model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))

model.add(Conv2D(256,kernel_size=(3,3),padding='valid',activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))

model.add(Flatten())

model.add(Dense(256,activation='relu'))
model.add(Dropout(0.1))

model.add(Dense(128,activation='relu'))
model.add(Dropout(0.1))


model.add(Dense(64,activation='relu'))
model.add(Dropout(0.1))

model.add(Dense(1, activation='sigmoid'))

model.summary()

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])



history = model.fit(train_ds,epochs=10,validation_data=validation_ds)

import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'], color='red', label='train')
plt.plot(history.history['val_accuracy'], color='blue', label='validation')
plt.legend()
plt.show()

import matplotlib.pyplot as plt
plt.plot(history.history['loss'], color='red', label='train')
plt.plot(history.history['val_loss'], color='blue', label='validation')
plt.legend()
plt.show()

import cv2

test_img = cv2.imread('/content/cat2.jpg')

plt.imshow(test_img)

test_img.shape

test_img=cv2.resize(test_img, (256, 256))

test_input=test_img.reshape(1, 256, 256, 3)

model.predict(test_input)

test_img3=cv2.imread('/content/dog.jpg')

plt.imshow(test_img3)

test_img3=cv2.resize(test_img3, (256, 256))

input_img3=test_img3.reshape(1, 256, 256, 3)

model.predict(input_img3)

test_img2=cv2.imread('/content/dog2.jpg')

plt.imshow(test_img2)

test_img2.shape

test_img2=cv2.resize(test_img2, (256,256))

input_img2=test_img2.reshape(1, 256, 256, 3)

model.predict(input_img2)



